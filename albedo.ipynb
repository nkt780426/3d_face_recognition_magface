{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c6f8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:44:18.731566Z",
     "iopub.status.busy": "2024-12-23T18:44:18.731295Z",
     "iopub.status.idle": "2024-12-23T18:44:37.075895Z",
     "shell.execute_reply": "2024-12-23T18:44:37.074927Z"
    },
    "papermill": {
     "duration": 18.351133,
     "end_time": "2024-12-23T18:44:37.077621",
     "exception": false,
     "start_time": "2024-12-23T18:44:18.726488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 15:10:17.366797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 15:10:18.045353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import albumentations as A\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from going_modular.dataloader.multitask import create_multitask_datafetcher\n",
    "from going_modular.model.MTLFaceRecognition import MTLFaceRecognition\n",
    "from going_modular.loss.MultiTaskLoss import MultiTaskLoss\n",
    "from going_modular.train_eval.train import fit\n",
    "from going_modular.utils.transforms import RandomResizedCropRect, GaussianNoise\n",
    "from going_modular.utils.MultiMetricEarlyStopping import MultiMetricEarlyStopping\n",
    "from going_modular.utils.ModelCheckPoint import ModelCheckpoint\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "CONFIGURATION = {\n",
    "    'type': 'albedo',\n",
    "    \n",
    "    # Thư mục\n",
    "    'dataset_dir': './Dataset',\n",
    "    'checkpoint_dir': './checkpoint/multi/',\n",
    "    \n",
    "    # Cấu hình train\n",
    "    'device': device,\n",
    "    'epochs': 39,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 16,\n",
    "    'image_size': 256,\n",
    "    'base_lr': 1e-4,\n",
    "    \n",
    "    # Cấu hình network\n",
    "    'backbone': 'miresnet18',\n",
    "    'embedding_size': 512,\n",
    "    'num_classes': None,\n",
    "    'loss_gender_weight': 30,\n",
    "    'loss_da_gender_weight': 30,\n",
    "    'loss_emotion_weight': 10,\n",
    "    'loss_da_emotion_weight': 10,\n",
    "    'loss_pose_weight': 30,\n",
    "    'loss_da_pose_weight': 30,\n",
    "    'loss_spectacles_weight': 5,\n",
    "    'loss_da_spectacles_weight': 5,\n",
    "    'loss_facial_hair_weight': 5,\n",
    "    'loss_da_facial_hair_weight': 5,\n",
    "}\n",
    "\n",
    "CONFIGURATION['num_classes'] = len(os.listdir('./Dataset/Albedo/train'))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    RandomResizedCropRect(256),\n",
    "    GaussianNoise(),\n",
    "], additional_targets={\n",
    "    'albedo': 'image',\n",
    "    'depthmap': 'image'\n",
    "})\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=CONFIGURATION['image_size'], width=CONFIGURATION['image_size'])\n",
    "], additional_targets={\n",
    "    'albedo': 'image',\n",
    "    'depthmap': 'image'\n",
    "})\n",
    "\n",
    "train_dataloader, test_dataloader, train_weight_class = create_multitask_datafetcher(CONFIGURATION, train_transform, test_transform)\n",
    "model = MTLFaceRecognition(CONFIGURATION['backbone'], CONFIGURATION['num_classes'])\n",
    "\n",
    "criterion = MultiTaskLoss(os.path.join(CONFIGURATION['dataset_dir'], 'train_set.csv'), CONFIGURATION)\n",
    "optimizer = Adam(model.parameters(), lr=CONFIGURATION['base_lr'])\n",
    "# Khởi tạo scheduler\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=40, T_mult=1, eta_min=1e-6)\n",
    "\n",
    "earlystop_dir = os.path.abspath(CONFIGURATION['checkpoint_dir'] + CONFIGURATION['type'] + '/models')\n",
    "\n",
    "early_stopping = MultiMetricEarlyStopping(\n",
    "    monitor_keys=['cosine_auc', 'euclidean_auc'],\n",
    "    patience=1000,\n",
    "    mode='max',\n",
    "    verbose=0,\n",
    "    save_dir=earlystop_dir,\n",
    "    start_from_epoch=0\n",
    ")      \n",
    "checkpoint_path = os.path.abspath(CONFIGURATION['checkpoint_dir'] + CONFIGURATION['type'] + '/models/checkpoint.pth')\n",
    "modle_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f42c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 58.9902    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 22.1865    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0597657 │ 0.12612559529952705  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.651081  │ 0.6152159888297319   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.185627  │ 0.1835680864751339   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.28195   │ 0.3299894407391548   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0233992 │ 0.027560903457924724 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0389194 │ 0.08223273837938905  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.221335  │ 0.24093020521104336  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.385954  │ 0.34814059920609     │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.142263  │ 0.13691704254597425  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  1.03704   │ 1.248690478503704    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.656107  │ 0.633372432459019    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.69959   │ 0.5780841696679576   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 2:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 55.1762    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 23.6778    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0549446 │ 0.06590527552179992  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.486142  │ 0.12164120678789914  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.183088  │ 0.1836439184844494   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.345895  │ 0.4058065488934517   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0228502 │ 0.022644321667030454 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.038998  │ 0.060888421488925815 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.214761  │ 0.25714174285531044  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.420309  │ 0.519857857376337    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0981451 │ 0.12545334082096815  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.890899  │ 0.5376903004944324   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.664675  │ 0.6038111087848913   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.68041   │ 0.6273815160227171   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 3:\n",
      "╒═════════════════════╤════════════╤═════════════════════╕\n",
      "│ Metric              │      Train │ Test                │\n",
      "╞═════════════════════╪════════════╪═════════════════════╡\n",
      "│ loss                │ 45.2069    │ -                   │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_id             │ 23.6432    │ -                   │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_gender         │  0.0526827 │ 0.05515570880379528 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_gender      │  0.145947  │ 0.1070253518410027  │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_emotion        │  0.182655  │ 0.18539625965058804 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_emotion     │  0.477227  │ 0.2672561686486006  │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_pose           │  0.0229656 │ 0.02379753766581416 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_pose        │  0.0611728 │ 0.0911869085393846  │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_facial_hair    │  0.21521   │ 0.22024678625166416 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_facial_hair │  0.711094  │ 0.49310866091400385 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_spectacles     │  0.100817  │ 0.07820335356518626 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_spectacles  │  0.269262  │ 0.15424528252333403 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_id_cosine       │  0.721683  │ 0.6155556643872904  │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_id_euclidean    │  0.73388   │ 0.6348581631718951  │\n",
      "╘═════════════════════╧════════════╧═════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 4:\n",
      "╒═════════════════════╤════════════╤═════════════════════╕\n",
      "│ Metric              │      Train │ Test                │\n",
      "╞═════════════════════╪════════════╪═════════════════════╡\n",
      "│ loss                │ 39.8512    │ -                   │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_id             │ 24.5042    │ -                   │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_gender         │  0.0443928 │ 0.05386125051882118 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_gender      │  0.0926169 │ 0.07379910792224109 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_emotion        │  0.178473  │ 0.18428609520196915 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_emotion     │  0.224826  │ 0.20229121670126915 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_pose           │  0.0231654 │ 0.03317196085117757 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_pose        │  0.0779236 │ 0.17016749689355493 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_facial_hair    │  0.205583  │ 0.19978860206902027 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_facial_hair │  0.333967  │ 0.3847474828362465  │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_spectacles     │  0.0858248 │ 0.09114465722814202 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ loss_da_spectacles  │  0.208837  │ 0.31581530533730984 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                 │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_id_cosine       │  0.676421  │ 0.6899692189207559  │\n",
      "├─────────────────────┼────────────┼─────────────────────┤\n",
      "│ auc_id_euclidean    │  0.687436  │ 0.705250384875123   │\n",
      "╘═════════════════════╧════════════╧═════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 5:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 39.4386    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 24.4626    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0353132 │ 0.04411875794176012  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0722636 │ 0.07185810315422714  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.177476  │ 0.1718489732593298   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.195801  │ 0.18827890045940876  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.022758  │ 0.025760125136002898 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.102524  │ 0.08972963877022266  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.197235  │ 0.223403912037611    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.272126  │ 0.23197130672633648  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0808339 │ 0.08330018306151032  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.301285  │ 0.2034588512033224   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.665903  │ 0.7433399615782569   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.672727  │ 0.7371005978505417   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 6:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 36.9489    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 25.0405    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0296651 │ 0.03863476146943867  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.061903  │ 0.06678937759716064  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.17326   │ 0.1757660787552595   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.191821  │ 0.18514362163841724  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0206377 │ 0.0199854732491076   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0516324 │ 0.046245189383625984 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.178037  │ 0.18853014800697565  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.236436  │ 0.2302059531211853   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0695773 │ 0.10846261912956834  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.184435  │ 0.19571650587022305  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.692896  │ 0.7497997935539288   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.695805  │ 0.7533859780802545   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 7:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 35.9959    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 24.8529    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0285289 │ 0.036137052869889885 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.062249  │ 0.06597199640236795  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.168947  │ 0.1699323197826743   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.186501  │ 0.1848819274455309   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0191001 │ 0.01953788148239255  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0294074 │ 0.027040180284529924 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.152548  │ 0.16415548976510763  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.22845   │ 0.22853024117648602  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0693846 │ 0.07138420175760984  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.231613  │ 0.2450643042102456   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.798647  │ 0.7940125815179415   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.785781  │ 0.7921469521918211   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 8:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 34.411     │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 23.8784    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0240858 │ 0.02657175820786506  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0592061 │ 0.06098882993683219  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.165847  │ 0.16010993253439665  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.184444  │ 0.18480301834642887  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0182905 │ 0.018384606344625354 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0232133 │ 0.0241909334436059   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.125221  │ 0.18018636479973793  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.214325  │ 0.23004116863012314  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0583511 │ 0.05612243665382266  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.259271  │ 0.2585684508085251   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.903386  │ 0.8163113402917054   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.880165  │ 0.8037272386339607   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 9:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 32.2104    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 22.2048    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0214319 │ 0.033031905244570225 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0569245 │ 0.06360298756044358  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.155821  │ 0.1716161984950304   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.181737  │ 0.18378833308815956  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0167632 │ 0.016990348231047392 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0230383 │ 0.023867771727964282 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.116085  │ 0.1754380175843835   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.201293  │ 0.21542487479746342  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.053955  │ 0.0742916000308469   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.245727  │ 0.21998860873281956  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.922133  │ 0.844921060892047    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.912155  │ 0.8306474722694274   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 10:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 30.0913    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 20.531     │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0175087 │ 0.026387043442809954 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0580954 │ 0.06327352987136692  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.150776  │ 0.19394401088356972  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.179246  │ 0.18393500801175833  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0154702 │ 0.01765194139443338  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0229729 │ 0.02401964762248099  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.102603  │ 0.16090928576886654  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.190571  │ 0.221023578196764    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0494549 │ 0.06126039708033204  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.225101  │ 0.2086911043152213   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.956123  │ 0.8950507164972102   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.937793  │ 0.8665852562539015   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 11:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 27.8964    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 18.6341    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0151666 │ 0.0212051899288781   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0598401 │ 0.06733919167891145  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.141789  │ 0.16144687868654728  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.176393  │ 0.17774243466556072  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0141255 │ 0.016449159709736705 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0232952 │ 0.024856793927028775 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0989545 │ 0.17997543700039387  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.185446  │ 0.21472706459462643  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0437873 │ 0.04811006807722151  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.21334   │ 0.20153139904141426  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.983098  │ 0.8912322786802369   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.962078  │ 0.8817208358252744   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 12:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 26.1233    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 16.9861    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0129885 │ 0.021722551668062806 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0631974 │ 0.07015196280553937  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.137335  │ 0.1616542600095272   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.174261  │ 0.17755683045834303  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0131805 │ 0.015340082929469645 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0230123 │ 0.023756279377266765 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0965749 │ 0.13277934025973082  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.185872  │ 0.21557114645838737  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0352358 │ 0.052703137625940144 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.212279  │ 0.20456738863140345  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.987277  │ 0.8598604324394552   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.979467  │ 0.9156290609153833   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 13:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 24.6699    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 15.4937    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0129144 │ 0.017267559247557074 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.066787  │ 0.07362850231584162  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.135442  │ 0.1887443009763956   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.173463  │ 0.17829843424260616  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0120847 │ 0.015035758726298809 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0223308 │ 0.023643077816814184 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0923794 │ 0.12803569249808788  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.192428  │ 0.2208449374884367   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0364824 │ 0.09921726072207093  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211432  │ 0.20510976575315     │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.983367  │ 0.8741212240247478   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.970251  │ 0.8774036672290213   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 14:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 22.8872    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 13.7971    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0109444 │ 0.01735971955349669  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0677892 │ 0.07218602695502341  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.130412  │ 0.16778486222028732  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.173343  │ 0.1749808257445693   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0116748 │ 0.015198938897810876 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0221833 │ 0.02313925768248737  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0845782 │ 0.11575850658118725  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.204018  │ 0.22678127884864807  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.03637   │ 0.050295235007070005 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209997  │ 0.20527567807585     │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.9965    │ 0.9235404108821749   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.988597  │ 0.9260220371701582   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 15:\n",
      "╒═════════════════════╤════════════╤══════════════════════╕\n",
      "│ Metric              │      Train │ Test                 │\n",
      "╞═════════════════════╪════════════╪══════════════════════╡\n",
      "│ loss                │ 21.9513    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_id             │ 12.8885    │ -                    │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0106117 │ 0.01974233830696903  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0692195 │ 0.07301380694843829  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.124813  │ 0.17513599712401628  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.174737  │ 0.17745952121913433  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0104523 │ 0.017353886738419533 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0218477 │ 0.023122496204450727 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0829265 │ 0.1329567739740014   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.211545  │ 0.23280655406415462  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.035299  │ 0.047580744489096105 │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.210891  │ 0.20536222122609615  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1         │ 1.0                  │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.997258  │ 0.9293866162586782   │\n",
      "├─────────────────────┼────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.98985   │ 0.9292519964546719   │\n",
      "╘═════════════════════╧════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 16:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 20.7007     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │ 11.6511     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00889234 │ 0.018461986997863278 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.070043   │ 0.07443067850545049  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.124337   │ 0.20663260854780674  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.175897   │ 0.17768795043230057  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00986736 │ 0.015401350450702012 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0216586  │ 0.022856354480609298 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0801278  │ 0.11636522691696882  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.227461   │ 0.23874078318476677  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0280637  │ 0.049984322977252305 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.21102    │ 0.20480550918728113  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.997316   │ 0.9441406321204777   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.990028   │ 0.935898770443627    │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 17:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 19.3891     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │ 10.4123     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00788152 │ 0.01329682199866511  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0693011  │ 0.07241321168839931  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.117033   │ 0.1930883750319481   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.17837    │ 0.1767061809077859   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00907651 │ 0.01400324737187475  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0214704  │ 0.0226976634003222   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.073955   │ 0.11751000490039587  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.244646   │ 0.24611175619065762  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0277294  │ 0.046440900885500014 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211847   │ 0.20429212134331465  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.998331   │ 0.91951185793969     │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.993511   │ 0.918098455109437    │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 18:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 18.646      │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  9.78652    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00611649 │ 0.015469201644009445 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0686505  │ 0.07270277966745198  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.112854   │ 0.1997568104416132   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.179508   │ 0.1801573410630226   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00853818 │ 0.017802797839976847 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0212459  │ 0.02273249812424183  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0684059  │ 0.11822808906435966  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.25478    │ 0.24535711482167244  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.026929   │ 0.05302484944695607  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209753   │ 0.2043549157679081   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.998466   │ 0.9578653977942674   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.995047   │ 0.935471770783123    │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 19:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 17.8863     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  9.01451    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00763113 │ 0.014124961337074637 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0673855  │ 0.07172274845652282  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.111175   │ 0.21109675522893667  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.182242   │ 0.1811782792210579   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00818947 │ 0.015022842097096145 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0214963  │ 0.02260808926075697  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0694242  │ 0.11707946192473173  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.257486   │ 0.24008896201848984  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0227373  │ 0.04610639420570806  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209671   │ 0.20501169934868813  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.998873   │ 0.9637889779854069   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.992508   │ 0.9502690702814875   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 20:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 17.0238     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  8.37151    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0045925  │ 0.01167441884172149  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0669703  │ 0.07062729680910707  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.105027   │ 0.17979523073881865  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.186226   │ 0.18283187225461006  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00738059 │ 0.014563940989319235 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0209914  │ 0.022766443667933345 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0637744  │ 0.10718565993010998  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.247544   │ 0.23525747563689947  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.025598   │ 0.04563221405260265  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211425   │ 0.20375188533216715  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999082   │ 0.9452082384701385   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.995577   │ 0.9380210337847795   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 21:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 16.2494     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  7.66599    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00460604 │ 0.013293268115376122 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0661688  │ 0.06912660575471818  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.104579   │ 0.19534036982804537  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.188996   │ 0.1844305070117116   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00692727 │ 0.015113351051695645 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0209789  │ 0.022695148130878806 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.063362   │ 0.10585269704461098  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.239379   │ 0.22913793846964836  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0244211  │ 0.05077294091461226  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.210278   │ 0.2057170756161213   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999351   │ 0.9599648776932912   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.996418   │ 0.9475896058235405   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 22:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 15.5392     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  7.05751    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00426937 │ 0.012719987294985913 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0653416  │ 0.0698490934446454   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.104626   │ 0.22170690912753344  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.192869   │ 0.18602229095995426  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00628476 │ 0.016073918843176216 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0207772  │ 0.02262357552535832  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0584984  │ 0.1008198787458241   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.230861   │ 0.22581261303275824  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0206759  │ 0.04355924966512248  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211268   │ 0.2062611412256956   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999493   │ 0.9618032963615735   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.996286   │ 0.9520617379242207   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 23:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 15.2361     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  6.82865    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00427974 │ 0.01277244242373854  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0658242  │ 0.06928120437078178  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0973779  │ 0.2430078126490116   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.194215   │ 0.1886192373931408   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0060808  │ 0.018711603246629238 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.020699   │ 0.022667049197480083 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0597313  │ 0.10950304940342903  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.226048   │ 0.22348263021558523  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0195856  │ 0.04782847862225026  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211632   │ 0.20535164698958397  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999808   │ 0.9718426060516963   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.997521   │ 0.9547409222578793   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 24:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 14.5473     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  6.19603    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00387203 │ 0.012662806700973306 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0650823  │ 0.06915902742184699  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0980984  │ 0.20018063485622406  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.196991   │ 0.18944242596626282  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00586326 │ 0.01692337420536205  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.02085    │ 0.022830366622656584 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0520843  │ 0.1188828069716692   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.222581   │ 0.22167629096657038  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0208362  │ 0.047247283859178424 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.210572   │ 0.20533903129398823  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999552   │ 0.9686430874615091   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.997217   │ 0.9542945762854826   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 25:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 13.8641     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  5.71143    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00266245 │ 0.01127752140746452  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0647814  │ 0.06861846591345966  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0875865  │ 0.2711337674409151   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.195769   │ 0.1884114257991314   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00531595 │ 0.020596673479303718 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0207978  │ 0.02292850357480347  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0515702  │ 0.12359700072556734  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219913   │ 0.2223573476076126   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0201117  │ 0.04659057408571243  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.21088    │ 0.20444235671311617  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999718   │ 0.9720633246900784   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.99772    │ 0.9542030877971992   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 26:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 13.6714     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  5.44059    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00300123 │ 0.009671209583757445 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0654887  │ 0.0685968161560595   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0909049  │ 0.2299211509525776   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.196734   │ 0.18861718568950891  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00637239 │ 0.013243751600384712 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0207707  │ 0.022742824163287878 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0460194  │ 0.10475568100810051  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219592   │ 0.22135517187416553  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0197908  │ 0.04492864181520417  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211679   │ 0.204884497448802    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999623   │ 0.9755826043730788   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.997495   │ 0.9540929050554228   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 27:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 13.0691     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  4.99426    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00277547 │ 0.010672525275367661 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0642181  │ 0.06847767834551632  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0831519  │ 0.24117456004023552  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.195758   │ 0.18967205565422773  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00482319 │ 0.01581231679301709  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0207292  │ 0.022852993570268154 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0532207  │ 0.11217139940708876  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.22034    │ 0.22171830013394356  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0172578  │ 0.044311427627690136 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211062   │ 0.20553180761635303  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999931   │ 0.9626502670146805   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998279   │ 0.943036025890637    │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 28:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 12.8915     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  4.81987    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00353843 │ 0.009825931694649626 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0650737  │ 0.06837296625599265  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0839263  │ 0.2603197814896703   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.194657   │ 0.1893811346963048   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00443498 │ 0.018312344676814973 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0207299  │ 0.022990359691902995 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0464482  │ 0.10433828830718994  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.218785   │ 0.22048806864768267  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0177533  │ 0.04334580560680479  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.211515   │ 0.20483165327459574  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999915   │ 0.9638863595166823   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998463   │ 0.9433471432973054   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 29:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 12.5201     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  4.50884    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00315282 │ 0.009704510164738167 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0643541  │ 0.06816596374846995  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0780218  │ 0.2075588321313262   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.19437    │ 0.18817001953721046  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00461156 │ 0.02119576625409536  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0209726  │ 0.0231156419031322   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0500952  │ 0.10332905873656273  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219031   │ 0.22067273873835802  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0195308  │ 0.04428191517945379  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.210259   │ 0.2044446151703596   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.9999     │ 0.9610973299466747   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998647   │ 0.9433227203195369   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 30:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 12.1982     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  4.28125    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00248139 │ 0.008925525027734693 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0641245  │ 0.06784761697053909  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0781494  │ 0.20886388793587685  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.192154   │ 0.18861139565706253  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00411338 │ 0.01739967631874606  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0209118  │ 0.023082849103957415 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0454244  │ 0.12101920694112778  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219211   │ 0.22106820158660412  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.017763   │ 0.05057189436047338  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.2106     │ 0.20471022184938192  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.99995    │ 0.9589404177871083   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998736   │ 0.9424796484540128   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 31:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 12.0041     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  4.15426    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00219635 │ 0.008031669749470893 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.064241   │ 0.0681135249324143   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.072186   │ 0.21819744817912579  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.192111   │ 0.18819275498390198  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00435615 │ 0.018377613741904497 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0208529  │ 0.023134136106818914 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0457147  │ 0.12403377518057823  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.218279   │ 0.22082067839801311  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.017702   │ 0.04516666621202603  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209796   │ 0.20443427469581366  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999973   │ 0.9671592195490688   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998986   │ 0.9475593936104771   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 32:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.6333     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.86423    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00229987 │ 0.008180797885870561 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0641342  │ 0.0678839492611587   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0677401  │ 0.2255144575610757   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.191314   │ 0.18833866529166698  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00419459 │ 0.01840018024086021  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0210437  │ 0.023148830281570554 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0390876  │ 0.10522296838462353  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219847   │ 0.22116120345890522  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0169218  │ 0.04597647741320543  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209811   │ 0.20461424626410007  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999914   │ 0.9603564804939849   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998271   │ 0.9453618764702509   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 33:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.6733     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.86437    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.0024868  │ 0.007487912684155162 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0641542  │ 0.06791419140063226  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0677779  │ 0.1993873966857791   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.19113    │ 0.18770844489336014  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00411274 │ 0.01892127637984231  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0211493  │ 0.02322081639431417  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0443691  │ 0.10317729972302914  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.220208   │ 0.22049716860055923  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0186201  │ 0.048914329963736236 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209352   │ 0.2045536059886217   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999981   │ 0.9652169258911444   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.999115   │ 0.9452408090480217   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 34:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.5375     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.75493    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00234362 │ 0.010192180565354647 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0640471  │ 0.06799364415928721  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0669085  │ 0.22505795396864414  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.190649   │ 0.18755734339356422  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00383121 │ 0.018849970190785825 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.021235   │ 0.02328005386516452  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.044959   │ 0.12101409398019314  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219541   │ 0.22133852541446686  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0187668  │ 0.04271230613812804  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209383   │ 0.20506728161126375  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999967   │ 0.9664877908418333   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.998861   │ 0.9456367571658904   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 35:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.3268     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.63579    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00211708 │ 0.009946473186573712 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0640597  │ 0.06804091623052955  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0627084  │ 0.21280976571142673  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.189764   │ 0.18734223023056984  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00348992 │ 0.020401037676492706 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0212429  │ 0.02326546353287995  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0417514  │ 0.11094559449702501  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219137   │ 0.22073206305503845  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.017396   │ 0.04553283139830455  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209513   │ 0.20449850149452686  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999945   │ 0.9665998222995842   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.999021   │ 0.9479402379692241   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 36:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.1693     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.4914     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00223342 │ 0.008804827117273817 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0639996  │ 0.06810221145860851  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0648671  │ 0.2098829848691821   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.188795   │ 0.18737842701375484  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.0035531  │ 0.019188702251994982 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0212116  │ 0.023270243778824806 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0379545  │ 0.1169350054115057   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219381   │ 0.2208842933177948   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0154553  │ 0.043801881081890315 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209486   │ 0.20466403383761644  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999987   │ 0.9702947211321706   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.999214   │ 0.9496939714657409   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 37:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.2506     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.51799    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00236891 │ 0.012235188753038528 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0648282  │ 0.06807901454158127  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0630141  │ 0.21816968359053135  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.189962   │ 0.1874344889074564   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00364845 │ 0.019270629796665162 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.02132    │ 0.023291158489882946 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0404099  │ 0.10848965588957071  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.219195   │ 0.22068378329277039  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0190557  │ 0.04135588649660349  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.208918   │ 0.20467558596283197  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999978   │ 0.9701961799802373   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.999005   │ 0.9498699839369533   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 38:\n",
      "╒═════════════════════╤═════════════╤══════════════════════╕\n",
      "│ Metric              │       Train │ Test                 │\n",
      "╞═════════════════════╪═════════════╪══════════════════════╡\n",
      "│ loss                │ 11.0259     │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_id             │  3.38058    │ -                    │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_gender         │  0.00173291 │ 0.009755792758369353 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_gender      │  0.0639665  │ 0.06795535702258348  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_emotion        │  0.0621379  │ 0.2119802124798298   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_emotion     │  0.188338   │ 0.18737947009503841  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_pose           │  0.00360222 │ 0.01933341345284134  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_pose        │  0.0213308  │ 0.023342236410826445 │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_facial_hair    │  0.0363288  │ 0.11498727556318045  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_facial_hair │  0.220162   │ 0.22058143094182014  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_spectacles     │  0.0179855  │ 0.04121900393511169  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209849   │ 0.20472788624465466  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                  │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_cosine       │  0.999983   │ 0.9681398193990615   │\n",
      "├─────────────────────┼─────────────┼──────────────────────┤\n",
      "│ auc_id_euclidean    │  0.999187   │ 0.9480029576409176   │\n",
      "╘═════════════════════╧═════════════╧══════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n",
      "Epoch 39:\n",
      "╒═════════════════════╤═════════════╤═════════════════════╕\n",
      "│ Metric              │       Train │ Test                │\n",
      "╞═════════════════════╪═════════════╪═════════════════════╡\n",
      "│ loss                │ 11.0319     │ -                   │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_id             │  3.37495    │ -                   │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_gender         │  0.00203737 │ 0.01091746336533106 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_da_gender      │  0.0648704  │ 0.06797189055941999 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_emotion        │  0.0597915  │ 0.22346977051347494 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_da_emotion     │  0.189305   │ 0.18741893395781517 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_pose           │  0.00365897 │ 0.01972161786397919 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_da_pose        │  0.0211813  │ 0.02338619134388864 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_facial_hair    │  0.0379235  │ 0.1041943971067667  │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_da_facial_hair │  0.21959    │ 0.2206520363688469  │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_spectacles     │  0.0156811  │ 0.04076204006560147 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ loss_da_spectacles  │  0.209515   │ 0.20477241650223732 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_gender          │  1          │ 1.0                 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_spectacles      │  1          │ 1.0                 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_facial_hair     │  1          │ 1.0                 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_pose            │  1          │ 1.0                 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_emotion         │  1          │ 1.0                 │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_id_cosine       │  0.999993   │ 0.9701870960242607  │\n",
      "├─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ auc_id_euclidean    │  0.999222   │ 0.9481877880282796  │\n",
      "╘═════════════════════╧═════════════╧═════════════════════╛\n",
      "\u001b[36m\tSaving model and optimizer state to /media/vohoang/WorkSpace/ubuntu/projects/in-process/3d_face_recognition_magface/checkpoint/multi/albedo/models/checkpoint.pth\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fit(\n",
    "    conf=CONFIGURATION,\n",
    "    start_epoch=0,\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader, \n",
    "    test_dataloader=test_dataloader, \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,    \n",
    "    scheduler=scheduler, \n",
    "    early_stopping=early_stopping,\n",
    "    model_checkpoint=modle_checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97f2c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MTLFaceRecognition(\n",
       "  (backbone): MIResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=1)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "    (spectacles_fsm): AttentionModule(\n",
       "      (avg_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (max_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial): Sequential(\n",
       "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (channel): Sequential(\n",
       "        (0): Conv2d(7168, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (facial_hair_fsm): AttentionModule(\n",
       "      (avg_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (max_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial): Sequential(\n",
       "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (channel): Sequential(\n",
       "        (0): Conv2d(7168, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (emotion_fsm): AttentionModule(\n",
       "      (avg_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (max_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial): Sequential(\n",
       "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (channel): Sequential(\n",
       "        (0): Conv2d(7168, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (pose_fsm): AttentionModule(\n",
       "      (avg_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (max_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial): Sequential(\n",
       "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (channel): Sequential(\n",
       "        (0): Conv2d(7168, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (gender_fsm): AttentionModule(\n",
       "      (avg_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (max_spp): SPPModule(\n",
       "        (pool_blocks): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=1)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=2)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): AdaptiveMaxPool2d(output_size=3)\n",
       "            (1): Flatten(start_dim=1, end_dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (spatial): Sequential(\n",
       "        (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (channel): Sequential(\n",
       "        (0): Conv2d(7168, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (id_head): IdRecognitionModule(\n",
       "    (id_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (maglinear): MagLinear()\n",
       "  )\n",
       "  (gender_head): GenderDetectModule(\n",
       "    (gender_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (gender_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (emotion_head): EmotionDetectModule(\n",
       "    (emotion_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (emotion_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (facial_hair_head): FacialHairDetectModule(\n",
       "    (facial_hair_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (facial_hair_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (pose_head): PoseDetectModule(\n",
       "    (pose_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (pose_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (spectacles_head): SpectacleDetectModule(\n",
       "    (spectacle_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (spectacle_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (da_gender_head): GenderDetectModule(\n",
       "    (gender_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (gender_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (da_emotion_head): EmotionDetectModule(\n",
       "    (emotion_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (emotion_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (da_facial_hair_head): FacialHairDetectModule(\n",
       "    (facial_hair_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (facial_hair_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (da_pose_head): PoseDetectModule(\n",
       "    (pose_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (pose_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (da_spectacles_head): SpectacleDetectModule(\n",
       "    (spectacle_embedding): Sequential(\n",
       "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (spectacle_linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (grl_gender): GradientReverseLayer()\n",
       "  (grl_emotion): GradientReverseLayer()\n",
       "  (grl_facial_hair): GradientReverseLayer()\n",
       "  (grl_pose): GradientReverseLayer()\n",
       "  (grl_spectacles): GradientReverseLayer()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c888bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c40c23",
   "metadata": {},
   "source": [
    "emotion: sai task 0 toàn đoán thành task 2\n",
    "occlusion + pose: tăng khả năng phân biệt giữa các lớp\n",
    "spectales: tốt nhưng cần hơn\n",
    "facial_hair + gender: quá tốt không cần chỉnh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703da67",
   "metadata": {},
   "source": [
    "Gender (1), Spectacles (0), Facial_Hair (1), Pose(0), Emotion(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7928477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0687, 0.9313]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9725, 0.0275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0013, 0.9987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8904, 0.1096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9387, 0.0613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "image_path = './Dataset/Albedo/gallery/1003/2008-02-21_16-38-47.exr'\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(image_path, cv2.IMREAD_UNCHANGED), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "transfromed = test_transform(image=image)\n",
    "\n",
    "X = torch.from_numpy(transfromed['image']).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "x_id, x_gender, x_pose, x_emotion, x_facial_hair, x_spectacles = model.get_result(X)\n",
    "x_gender = torch.softmax(x_gender, dim=1)\n",
    "print(x_gender)\n",
    "x_spectacles = torch.softmax(x_spectacles, dim=1)\n",
    "print(x_spectacles)\n",
    "x_facial_hair = torch.softmax(x_facial_hair, dim=1)\n",
    "print(x_facial_hair)\n",
    "x_pose = torch.softmax(x_pose, dim=1)\n",
    "print(x_pose)\n",
    "x_emotion = torch.softmax(x_emotion, dim=1)\n",
    "print(x_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41c328",
   "metadata": {},
   "source": [
    "Gender (1), Spectacles (0), Facial_Hair (1), Pose(2), Occlusion (2),Emotion(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30edffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2285, 0.7715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8189, 0.1811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0703, 0.9297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1183, 0.1410, 0.7407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0961, 0.5510, 0.3529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.5269, 0.0341, 0.4390]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "image_path = './Dataset/Albedo/gallery/2186/2007-12-04_12-15-04.exr'\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(image_path, cv2.IMREAD_UNCHANGED), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "transfromed = test_transform(image=image)\n",
    "\n",
    "X = torch.from_numpy(transfromed['image']).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "x_id, x_gender, x_pose, x_emotion, x_facial_hair, x_occlusion, x_spectacles = model.get_embedding(X)\n",
    "x_gender = torch.softmax(x_gender, dim=1)\n",
    "print(x_gender)\n",
    "x_spectacles = torch.softmax(x_spectacles, dim=1)\n",
    "print(x_spectacles)\n",
    "x_facial_hair = torch.softmax(x_facial_hair, dim=1)\n",
    "print(x_facial_hair)\n",
    "x_pose = torch.softmax(x_pose, dim=1)\n",
    "print(x_pose)\n",
    "x_occlusion = torch.softmax(x_occlusion, dim=1)\n",
    "print(x_occlusion)\n",
    "x_emotion = torch.softmax(x_emotion, dim=1)\n",
    "print(x_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86351519",
   "metadata": {},
   "source": [
    "Gender (1), Spectacles (1), Facial_Hair (0), Pose(0), Occlusion (2),Emotion(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8e61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1420, 0.8580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0030, 0.9970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.8690, 0.1310]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4120, 0.4890, 0.0990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2312, 0.3471, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.6135, 0.0481, 0.3384]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "image_path = './Dataset/Albedo/gallery/1009/2008-02-18_08-50-39.exr'\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(image_path, cv2.IMREAD_UNCHANGED), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "transfromed = test_transform(image=image)\n",
    "\n",
    "X = torch.from_numpy(transfromed['image']).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "x_id, x_gender, x_pose, x_emotion, x_facial_hair, x_occlusion, x_spectacles = model.get_embedding(X)\n",
    "x_gender = torch.softmax(x_gender, dim=1)\n",
    "print(x_gender)\n",
    "x_spectacles = torch.softmax(x_spectacles, dim=1)\n",
    "print(x_spectacles)\n",
    "x_facial_hair = torch.softmax(x_facial_hair, dim=1)\n",
    "print(x_facial_hair)\n",
    "x_pose = torch.softmax(x_pose, dim=1)\n",
    "print(x_pose)\n",
    "x_occlusion = torch.softmax(x_occlusion, dim=1)\n",
    "print(x_occlusion)\n",
    "x_emotion = torch.softmax(x_emotion, dim=1)\n",
    "print(x_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc40bd",
   "metadata": {},
   "source": [
    "Gender (1), Spectacles (0), Facial_Hair (0), Pose(0), Occlusion (1),Emotion(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05f7a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1173, 0.8827]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.9733, 0.0267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7232, 0.2768]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3992, 0.3661, 0.2347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1896, 0.4835, 0.3269]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4071, 0.0306, 0.5623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "image_path = './Dataset/Albedo/gallery/1038/2009-07-10_09-49-50.exr'\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(image_path, cv2.IMREAD_UNCHANGED), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "transfromed = test_transform(image=image)\n",
    "\n",
    "X = torch.from_numpy(transfromed['image']).permute(2,0,1).unsqueeze(0).to(device)\n",
    "\n",
    "x_id, x_gender, x_pose, x_emotion, x_facial_hair, x_occlusion, x_spectacles = model.get_embedding(X)\n",
    "x_gender = torch.softmax(x_gender, dim=1)\n",
    "print(x_gender)\n",
    "x_spectacles = torch.softmax(x_spectacles, dim=1)\n",
    "print(x_spectacles)\n",
    "x_facial_hair = torch.softmax(x_facial_hair, dim=1)\n",
    "print(x_facial_hair)\n",
    "x_pose = torch.softmax(x_pose, dim=1)\n",
    "print(x_pose)\n",
    "x_occlusion = torch.softmax(x_occlusion, dim=1)\n",
    "print(x_occlusion)\n",
    "x_emotion = torch.softmax(x_emotion, dim=1)\n",
    "print(x_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f11c59",
   "metadata": {},
   "source": [
    "        # 0: nhìn trực diện (2471), 1: nhìn nghiêng 1 chút (326), 2: lệch 30-45 độ (77)\n",
    "        self.pose_loss = FocalLoss(alpha_weights={0: 0.0246, 1: 0.1863, 2: 0.7891}, gamma_weights={0: 1, 1: 0.5, 2: 0}, num_classes=3)\n",
    "        # 0: tóc che mặt (13), 1: tay che mặt (46), 2: không bị che khuất (2615)\n",
    "        self.occlusion_loss = FocalLoss(alpha_weights={0:0.7765, 1:0.2195, 2:0.0039}, gamma_weights={0: 0, 1: 0, 2: 1.5}, num_classes=3)\n",
    "        # 0: nhìn trực diện (2209), 1: các cảm xúc khác (249), 2: tích cực (416)\n",
    "        self.emotion_loss = FocalLoss(alpha_weights={0:0.0659, 1:0.5844, 2:0.3497}, gamma_weights={0: 0.5, 1: 0, 2: 0}, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db980546",
   "metadata": {},
   "source": [
    "CONFIGURATION = {\n",
    "    'type': 'albedo',\n",
    "    \n",
    "    # Thư mục\n",
    "    'dataset_dir': './Dataset',\n",
    "    'checkpoint_dir': './checkpoint/multi/',\n",
    "    \n",
    "    # Cấu hình train\n",
    "    'device': device,\n",
    "    'epochs': 39,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 16,\n",
    "    'image_size': 256,\n",
    "    'base_lr': 1e-4,\n",
    "    \n",
    "    # Cấu hình network\n",
    "    'backbone': 'miresnet18',\n",
    "    'embedding_size': 512,\n",
    "    'num_classes': None,\n",
    "    'loss_gender_weight': 10,\n",
    "    'loss_da_gender_weight': 10,\n",
    "    'loss_emotion_weight': 10,\n",
    "    'loss_da_emotion_weight': 10,\n",
    "    'loss_pose_weight': 20,\n",
    "    'loss_da_pose_weight': 20,\n",
    "    'loss_spectacles_weight': 5,\n",
    "    'loss_da_spectacles_weight': 5,\n",
    "    'loss_occlusion_weight': 20,\n",
    "    'loss_da_occlusion_weight': 20,\n",
    "    'loss_facial_hair_weight': 5,\n",
    "    'loss_da_facial_hair_weight': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56044d3",
   "metadata": {},
   "source": [
    "!zip -r output.zip checkpoint/new/concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44a509",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6338037,
     "sourceId": 10247612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17096.367763,
   "end_time": "2024-12-23T23:28:48.754749",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-23T18:43:52.386986",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
