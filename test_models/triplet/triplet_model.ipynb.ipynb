{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 18:28:15.779718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-20 18:28:17.377177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import os\n",
    "from going_modular.model.TripletFaceRecognition import EmbeddingNetConcatV3, TripletNetConcatV3\n",
    "from going_modular.dataloader.triplet import CustomExrDatasetConCatV3\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "import json\n",
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "CONFIGURATION = {\n",
    "    # Thư mục\n",
    "    'data_dir': '../3d_face_recognition_magface/Dataset',\n",
    "    'checkpoint': './checkpoint/new/concat_3/models/checkpoint.pth',\n",
    "    'recognition_dir': './Gallery/recognition',\n",
    "\n",
    "    # Cấu embedding\n",
    "    'embedding_size': 512,\n",
    "    'batch_size': 16,\n",
    "    \n",
    "    # Cấu hình khác\n",
    "    'image_size': 256,\n",
    "    'num_workers': 4,\n",
    "}\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=CONFIGURATION['image_size'], width=CONFIGURATION['image_size'])\n",
    "], additional_targets={\n",
    "    'albedo': 'image',\n",
    "    'depthmap': 'image'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatGalleryExrDatasetV3(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_dir:str, transform, metadata_path):\n",
    "        self.metadata_path = metadata_path\n",
    "        self.albedo_dir = Path(dataset_dir) / 'Albedo' / 'gallery'\n",
    "        self.depth_dir = Path(dataset_dir) / 'Depth_Map' / 'gallery'\n",
    "        self.normal_dir = Path(dataset_dir) / 'Normal_Map' / 'gallery'\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(self.albedo_dir))\n",
    "        \n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "        # Tạo danh sách các đường dẫn và id tương ứng\n",
    "        self.data = [\n",
    "            (\n",
    "                (\n",
    "                    Path(self.normal_dir, str(row['id']), f\"{row['session']}.exr\"),  # Đường dẫn albedo\n",
    "                    Path(self.albedo_dir, str(row['id']), f\"{row['session']}.exr\"),  # Đường dẫn normal\n",
    "                    Path(self.depth_dir, str(row['id']), f\"{row['session']}.exr\")   # Đường dẫn depth\n",
    "                ),\n",
    "                row['id']  # Lớp (label_index)\n",
    "            )\n",
    "            for _, row in metadata.iterrows()\n",
    "        ]\n",
    "        \n",
    "        self.paths, self.classes = zip(*self.data)\n",
    "        self.transform = transform\n",
    "\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    \n",
    "    # Nhận vào index mà dataloader muốn lấy\n",
    "    def __getitem__(self, index:int) -> Tuple[torch.Tensor, int]:\n",
    "        albedo_path, normal_path, depth_path = self.paths[index]\n",
    "        numpy_normal = self.__load_numpy_image(normal_path)\n",
    "        numpy_albedo = self.__load_numpy_image(albedo_path)\n",
    "        numpy_depth = self.__load_numpy_image(depth_path)\n",
    "        label = albedo_path.parent.name\n",
    "        label_index = self.classes.index(int(label))\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=numpy_normal, albedo=numpy_albedo, depthmap=numpy_depth)\n",
    "            numpy_normal = transformed['image']\n",
    "            numpy_albedo = transformed['albedo']\n",
    "            numpy_depth = transformed['depthmap']\n",
    "        \n",
    "        # Stack các tensor lại thành một tensor duy nhất\n",
    "        X = torch.stack((\n",
    "            torch.from_numpy(numpy_normal).permute(2, 0, 1),\n",
    "            torch.from_numpy(numpy_albedo).permute(2, 0, 1), \n",
    "            torch.from_numpy(numpy_depth).permute(2, 0, 1)\n",
    "        ), dim=0)\n",
    "        return X, label_index\n",
    "        \n",
    "        \n",
    "    def __load_numpy_image(self, image_path):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image at {image_path}\")\n",
    "        elif len(image.shape) == 2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif len(image.shape) == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "dataset = ConcatGalleryExrDatasetV3(CONFIGURATION['data_dir'], test_transform, '../3d_face_recognition_magface/test_models/multi/gallery.csv')\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=CONFIGURATION['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIGURATION['num_workers'],\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embedding to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_net = EmbeddingNetConcatV3(conf=CONFIGURATION)\n",
    "\n",
    "model = TripletNetConcatV3(embedding_net).to(device)\n",
    "checkpoint = torch.load(CONFIGURATION['checkpoint'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu dữ liệu vào gallery_db.csv...\n",
      "Lưu thành công dữ liệu vào gallery_db.csv.\n"
     ]
    }
   ],
   "source": [
    "# Chuyển sang chế độ đánh giá\n",
    "model.eval()\n",
    "\n",
    "# Lưu embedding và class vào CSV\n",
    "output_csv = \"gallery_db.csv\"\n",
    "print(f\"Lưu dữ liệu vào {output_csv}...\")\n",
    "\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"embedding\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, label_index in dataloader:\n",
    "            # Đưa batch lên GPU nếu có\n",
    "            X = X.to(device)\n",
    "\n",
    "            # Sinh embedding\n",
    "            embeddings = model.get_embedding(X).cpu().numpy()  # Chuyển về CPU\n",
    "\n",
    "            # Lấy nhãn tương ứng\n",
    "            labels = [dataset.classes[i] for i in label_index.numpy()]\n",
    "\n",
    "            # Lưu vào CSV\n",
    "            for embedding, label in zip(embeddings, labels):\n",
    "                embedding_str = json.dumps(embedding.tolist())  # Chuyển thành chuỗi JSON\n",
    "                writer.writerow([label, embedding_str])\n",
    "\n",
    "print(f\"Lưu thành công dữ liệu vào {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tính Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc(\n",
    "    dataloader: torch.utils.data.DataLoader, \n",
    "    model: torch.nn.Module, \n",
    "    device: str\n",
    "):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings_list = []\n",
    "        for batch in dataloader:\n",
    "            images, ids = batch\n",
    "            images = images.to(device)\n",
    "            embeddings = model.get_embedding(images)\n",
    "            \n",
    "            embeddings_list.append((ids, embeddings))\n",
    "        \n",
    "        # Concatenate all embeddings into one tensor\n",
    "        all_ids = torch.cat([x[0] for x in embeddings_list], dim=0)\n",
    "        all_embeddings = torch.cat([x[1] for x in embeddings_list], dim=0)\n",
    "        \n",
    "        euclidean_scores = []\n",
    "        euclidean_labels = []\n",
    "        cosine_scores = []\n",
    "        cosine_labels = []\n",
    "\n",
    "        # Compute pairwise Euclidean distance and cosine similarity\n",
    "        all_embeddings_norm = all_embeddings / all_embeddings.norm(p=2, dim=1, keepdim=True)\n",
    "        euclidean_distances = torch.cdist(all_embeddings, all_embeddings, p=2)  # Euclidean distance matrix\n",
    "        cosine_similarities = torch.mm(all_embeddings_norm, all_embeddings_norm.t())  # Cosine similarity matrix\n",
    "        \n",
    "        # Compute labels (same id = 0, different id = 1)\n",
    "        labels = (all_ids.unsqueeze(1) == all_ids.unsqueeze(0)).int().to(device)\n",
    "\n",
    "        # Flatten and filter results\n",
    "        euclidean_scores = euclidean_distances[torch.triu(torch.ones_like(labels), diagonal=1) == 1].cpu().numpy()\n",
    "        euclidean_labels = labels[torch.triu(torch.ones_like(labels), diagonal=1) == 1].cpu().numpy()\n",
    "        \n",
    "        cosine_scores = cosine_similarities[torch.triu(torch.ones_like(labels), diagonal=1) == 1].cpu().numpy()\n",
    "        cosine_labels = labels[torch.triu(torch.ones_like(labels), diagonal=1) == 1].cpu().numpy()\n",
    "        \n",
    "        # Compute ROC AUC for Euclidean distance\n",
    "        euclidean_true_labels = 1 - np.array(euclidean_labels)\n",
    "        euclidean_pred_scores = np.array(euclidean_scores)\n",
    "        fpr_euclidean, tpr_euclidean, thresholds_euclidean = roc_curve(euclidean_true_labels, euclidean_pred_scores)\n",
    "        roc_auc_euclidean = auc(fpr_euclidean, tpr_euclidean)\n",
    "\n",
    "        # Compute ROC AUC for Cosine similarity\n",
    "        cosine_true_labels = np.array(cosine_labels)\n",
    "        cosine_pred_scores = np.array(cosine_scores)\n",
    "        fpr_cosine, tpr_cosine, thresholds_cosine = roc_curve(cosine_true_labels, cosine_pred_scores)\n",
    "        roc_auc_cosine = auc(fpr_cosine, tpr_cosine)\n",
    "        \n",
    "        # Calculate accuracy for Euclidean distance\n",
    "        euclidean_optimal_idx = np.argmax(tpr_euclidean - fpr_euclidean) # Chọn ngưỡng tại điểm có giá trị tpr - fpr lớn nhất trên đường ROC, vì đây là nơi tối ưu hóa sự cân bằng giữa tỷ lệ phát hiện (TPR) và tỷ lệ báo động giả (FPR).\n",
    "        euclidean_optimal_threshold = thresholds_euclidean[euclidean_optimal_idx]\n",
    "        euclidean_pred_labels = (euclidean_pred_scores >= euclidean_optimal_threshold).astype(int)\n",
    "        euclidean_accuracy = accuracy_score(euclidean_true_labels, euclidean_pred_labels)\n",
    "\n",
    "        # Calculate accuracy for Cosine similarity\n",
    "        cosine_optimal_idx = np.argmax(tpr_cosine - fpr_cosine)\n",
    "        cosine_optimal_threshold = thresholds_cosine[cosine_optimal_idx]\n",
    "        cosine_pred_labels = (cosine_pred_scores >= cosine_optimal_threshold).astype(int)\n",
    "        cosine_accuracy = accuracy_score(cosine_true_labels, cosine_pred_labels)\n",
    "        \n",
    "    return roc_auc_euclidean, roc_auc_cosine, euclidean_accuracy, cosine_accuracy\n",
    "\n",
    "roc_auc_euclidean, roc_auc_cosine, euclidean_accuracy, cosine_accuracy = compute_roc_auc(dataloader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - Cosine: nan\n",
      "AUC - Euclidean: nan\n",
      "Accuracy - Cosine: nan\n",
      "Accuracy - Euclidean: nan\n"
     ]
    }
   ],
   "source": [
    "print(f'AUC - Cosine: {roc_auc_euclidean}')\n",
    "print(f'AUC - Euclidean: {roc_auc_euclidean}')\n",
    "print(f'Accuracy - Cosine: {roc_auc_euclidean}')\n",
    "print(f'Accuracy - Euclidean: {roc_auc_euclidean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tìm embedding gần nhất trong gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính khoảng cách Cosine\n",
    "def calculate_cosine_distances_torch(query_embedding, embeddings):\n",
    "    # Chuẩn hóa vector để tính cosine similarity\n",
    "    query_embedding = query_embedding / query_embedding.norm(dim=1, keepdim=True)\n",
    "    embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "    \n",
    "    # Tính cosine similarity\n",
    "    cosine_similarities = torch.mm(query_embedding, embeddings.T)\n",
    "    # Chuyển thành khoảng cách\n",
    "    return cosine_similarities\n",
    "\n",
    "# Tính khoảng cách Euclidean\n",
    "def calculate_euclidean_distances_torch(query_embedding, embeddings):\n",
    "    # Tính Euclidean Distance\n",
    "    euclidean_distances = torch.cdist(query_embedding, embeddings, p=2)\n",
    "    return euclidean_distances\n",
    "\n",
    "# Tìm top-k embedding gần nhất\n",
    "def find_top_k_neighbors_torch(query_embedding, embeddings, labels, device, k=5, distance_metric='cosine'):\n",
    "    query_embedding = torch.tensor(query_embedding, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "    embeddings = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, device=device)\n",
    "\n",
    "    if distance_metric == 'cosine':\n",
    "        distances = calculate_cosine_distances_torch(query_embedding, embeddings).squeeze(0)\n",
    "        # Lấy top-k (torch.topk trả giá trị nhỏ nhất nếu `largest=False`)\n",
    "        top_k_distances, top_k_indices = torch.topk(distances, k, largest=True)\n",
    "    elif distance_metric == 'euclidean':\n",
    "        distances = calculate_euclidean_distances_torch(query_embedding, embeddings).squeeze(0)\n",
    "        # Lấy top-k (torch.topk trả giá trị nhỏ nhất nếu `largest=False`)\n",
    "        top_k_distances, top_k_indices = torch.topk(distances, k, largest=False)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported distance metric. Choose 'cosine' or 'euclidean'.\")\n",
    "    \n",
    "\n",
    "    # Lấy nhãn của top-k\n",
    "    top_k_labels = labels[top_k_indices]\n",
    "    return top_k_distances.cpu().numpy(), top_k_labels.cpu().numpy()\n",
    "\n",
    "df = pd.read_csv('gallery_db.csv')\n",
    "\n",
    "# Chuyển chuỗi trong cột `Embedding` thành danh sách Python\n",
    "df['embedding'] = df['embedding'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Chuyển các danh sách trong cột `Embedding` thành mảng numpy\n",
    "embeddings = np.array(df['embedding'].tolist(), dtype=np.float32)\n",
    "\n",
    "# Giữ nguyên nhãn\n",
    "labels = df['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_k_accuracy(query_embedding, embeddings, labels, query_label, device, k=5, distance_metric='cosine'):\n",
    "    query_label = query_label.to(device)\n",
    "    query_label_index = dataset.classes[query_label.item()]\n",
    "    # Tính top-k nhãn gần nhất\n",
    "    _, top_k_labels = find_top_k_neighbors_torch(query_embedding, embeddings, labels, device, k, distance_metric)\n",
    "    \n",
    "    top_k_labels = torch.tensor(top_k_labels, device=device)\n",
    "    # Kiểm tra nếu nhãn thực tế nằm trong top-k\n",
    "    if torch.isin(query_label_index, top_k_labels).any():  # Kiểm tra nếu query_label có nằm trong top_k_labels\n",
    "        return 1  # Đúng\n",
    "    return 0  # Sai\n",
    "\n",
    "def calculate_recognition_accuracy(model, dataloader, gallery_embeddings, gallery_labels, device, top_k=5, distance_metric='cosine'):\n",
    "    correct_predictions_top_k = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    model.eval()  # Đảm bảo mô hình ở trạng thái eval\n",
    "\n",
    "    with torch.no_grad():  # Tắt gradient để tiết kiệm bộ nhớ\n",
    "        for query_images, query_labels in dataloader:\n",
    "            query_images = query_images.to(device)\n",
    "            query_labels = query_labels.to(device)\n",
    "\n",
    "            # Lấy embedding từ mô hình\n",
    "            query_embeddings = model.get_embedding(query_images)\n",
    "            \n",
    "            # Tính accuracy cho từng query trong batch\n",
    "            for idx, query_label in enumerate(query_labels):\n",
    "                query_embedding = query_embeddings[idx]  # Lấy embedding của ảnh tại index idx trong batch\n",
    "                \n",
    "                # Tính top-k accuracy\n",
    "                correct_predictions_top_k += calculate_top_k_accuracy(query_embedding, gallery_embeddings, gallery_labels, query_label, device, k=top_k, distance_metric=distance_metric)\n",
    "                total_predictions += 1\n",
    "\n",
    "    return correct_predictions_top_k / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_dataset = ConcatGalleryExrDatasetV3(CONFIGURATION['data_dir'], test_transform, '../3d_face_recognition_magface/test_models/multi/gallery_remaining.csv')\n",
    "\n",
    "recognition_dataloader = DataLoader(\n",
    "    recognition_dataset,\n",
    "    batch_size=CONFIGURATION['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIGURATION['num_workers'],\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 54.10%\n",
      "Top-5 Accuracy: 76.23%\n"
     ]
    }
   ],
   "source": [
    "# Tính top-1 accuracy\n",
    "accuracy_top_1 = calculate_recognition_accuracy(\n",
    "    model=model,\n",
    "    dataloader=recognition_dataloader,\n",
    "    gallery_embeddings=embeddings,\n",
    "    gallery_labels=labels,\n",
    "    device=device,\n",
    "    top_k=1,  # Top-1 accuracy\n",
    "    distance_metric='cosine'\n",
    ")\n",
    "\n",
    "# Tính top-5 accuracy\n",
    "accuracy_top_5 = calculate_recognition_accuracy(\n",
    "    model=model,\n",
    "    dataloader=recognition_dataloader,\n",
    "    gallery_embeddings=embeddings,\n",
    "    gallery_labels=labels,\n",
    "    device=device,\n",
    "    top_k=5,  # Top-5 accuracy\n",
    "    distance_metric='cosine'\n",
    ")\n",
    "\n",
    "print(f\"Top-1 Accuracy: {accuracy_top_1:.2%}\")\n",
    "print(f\"Top-5 Accuracy: {accuracy_top_5:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
